apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: rapidast-integration-pipeline
#  namespace: multiarch-tuning-ope-tenant
spec:
  description: >-
    Implement the RapidDAST scanning task in rh-trex to service as a proof of concept for users.
  params:
    - description: 'Snapshot of the application'
      name: SNAPSHOT
#      default: '{"components": [{"name":"multiarch-tuning-operator", "containerImage": "quay.io/redhat-user-workloads/multiarch-tuning-ope-tenant/multiarch-tuning-operator/multiarch-tuning-operator@sha256:{MY sha from pipelinerun}"}]}'
      type: string
  tasks:
    - name: provision-env
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/konflux-ci/build-definitions.git
          - name: revision
            value: main
          - name: pathInRepo
            value: task/eaas-provision-space/0.1/eaas-provision-space.yaml
      params:
        - name: ownerName
          value: $(context.pipelineRun.name)
        - name: ownerUid
          value: $(context.pipelineRun.uid)
    - name: deploy-app
      params:
        - name: SNAPSHOT
          value: "$(params.SNAPSHOT)"
      runAfter:
        - provision-env
      taskSpec:
        params:
          - name: SNAPSHOT
            type: string
        volumes:
          - name: credentials
            emptyDir: {}
        steps:
          # write the kubeconfig to a volume we can use in subsequent steps
          # and emptyDir volume will be exist for the lifetime of a single taskRun
          - name: get-kubeconfig
            image: quay.io/konflux-ci/konflux-test:latest
            env:
              - name: KUBECONFIG
                value: /credentials/kubeconfig.yml
              - name: KUBECONFIG_VALUE
                valueFrom:
                  secretKeyRef:
                    name: "$(tasks.provision-env.results.secretRef)"
                    key: kubeconfig
            volumeMounts:
              - name: credentials
                mountPath: /credentials
            script: |
              #!/bin/bash
              set -euxo pipefail

              cat <<< "$KUBECONFIG_VALUE" > "$KUBECONFIG"
              echo "Wrote kubeconfig for new environment to $KUBECONFIG"

          # we need to copy the pull secret into our fresh test environment
          # for the SNAPSHOT image stored in a private quay repo
          - name: copy-pull-secret
            image: quay.io/konflux-ci/konflux-test:latest
            env:
              - name: DEST_KUBECONFIG
                value: /credentials/kubeconfig.yml
              # used to pull SNAPSHOT image, should already exist in user namespace
              - name: PULL_SECRET
                value: imagerepository-for-multiarch-tuning-operator-multiarch-tuning-operator-image-pull
            volumeMounts:
              - name: credentials
                mountPath: /credentials
            script: |
              #!/bin/bash
              set -euxo pipefail

              oc get secrets $PULL_SECRET -o json | jq 'del(.metadata.creationTimestamp,
                .metadata.uid, .metadata.resourceVersion,
                .metadata.annotations."kubectl.kubernetes.io/last-applied-configuration",
                .metadata.namespace)' > /tmp/pull-secret.json
              oc --kubeconfig=$DEST_KUBECONFIG apply -f /tmp/pull-secret.json
              oc --kubeconfig=$DEST_KUBECONFIG secret link --for=pull default $PULL_SECRET

          # deploy an instance of our app using the snapshot image in our test env
          - name: deploy-app
            image: quay.io/operator-framework/operator-sdk:latest
            env:
              - name: SNAPSHOT
                value: "$(params.SNAPSHOT)"
              - name: KUBECONFIG
                value: /credentials/kubeconfig.yml
            volumeMounts:
              - name: credentials
                mountPath: /credentials
            script: |
              #!/bin/bash
              set -euxo pipefail

              # Download jq binary instead of installing via package manager
              curl -L -o /usr/local/bin/jq https://github.com/jqlang/jq/releases/download/jq-1.7.1/jq-linux-amd64
              chmod +x /usr/local/bin/jq

              # Download oc (OpenShift CLI) binary
              curl -L -o /tmp/oc.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/openshift-client-linux.tar.gz
              tar -xzf /tmp/oc.tar.gz -C /usr/local/bin oc
              chmod +x /usr/local/bin/oc
              rm /tmp/oc.tar.gz

              OO_BUNDLE=$(echo "$SNAPSHOT" | jq -r '.components[1].containerImage')
              NAMESPACE=$(oc project --short)
              echo "Deploying bundle $OO_BUNDLE to namespace $NAMESPACE"

              # Grant necessary permissions to the namespace-manager service account for OLM operations
              # This is needed for operator-sdk run bundle to create CatalogSource, OperatorGroup, and Subscription
              SA_NAME=$(oc whoami)
              echo "Granting cluster-admin to ${SA_NAME} for OLM operations..."
              oc adm policy add-cluster-role-to-user cluster-admin "${SA_NAME}"

              operator-sdk run bundle "$OO_BUNDLE" -n "$NAMESPACE" --timeout=5m

              # Wait for the operator installation (CSV) to succeed, which is more reliable than waiting for a deployment
              echo "Waiting for operator to be installed..."
              # First, get the name of the CSV that the subscription is installing
              CSV_NAME=""
              for i in {1..10}; do
              # The subscription name is usually the same as the package name from the bundle
                CSV_NAME=$(oc get subscription -n "$NAMESPACE" -l operators.coreos.com/oc-create-deployment-78db6-multiarch-tuning-operator.multiarch-tuning-ope-tenant -o jsonpath='{.items[0].status.installedCSV}' || true)
                if [[ -n "$CSV_NAME" ]]; then
                echo "Found installed CSV: $CSV_NAME"
                break
                fi
                echo "Waiting for subscription to report installed CSV..."
                sleep 15
                done
                
                if [[ -z "$CSV_NAME" ]]; then
                echo "Timed out waiting for subscription to be created and report installed CSV."
                oc get all -n "$NAMESPACE"
                exit 1
              fi
                      
              oc wait --for=condition=Succeeded csv/"$CSV_NAME" -n "$NAMESPACE" --timeout=5m
              echo "Operator deployment successful."
    - name: setup-test
      runAfter: [deploy-app]
      taskSpec:
        results:
          - name: authenticated_url
            description: "The authenticated URL for the Dinosaur API"
          - name: config_path
            description: "Path to the RapiDAST configuration file"
        sidecars:
          - name: port-forward
            image: registry.redhat.io/openshift4/ose-cli:latest
            env:
              - name: KUBECONFIG_VALUE
                valueFrom:
                  secretKeyRef:
                    name: "$(tasks.provision-env.results.secretRef)"
                    key: kubeconfig
              - name: OCM_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: ocm
                    key: ocmtoken
            ports:
              - containerPort: 8000
            script: |
              #!/usr/bin/env bash
              set -ex 
              cat <<< "$KUBECONFIG_VALUE" > /tmp/cfg
              export KUBECONFIG=/tmp/cfg
              
              echo "Starting port-forward for service/trex on port 8000..."
              oc port-forward --address=0.0.0.0 --kubeconfig /tmp/cfg svc/trex 8000:8000
        steps:
          - name: get-url
            image: registry.redhat.io/openshift4/ose-cli:latest
            env:
              - name: OCM_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: ocm
                    key: ocmtoken
            script: |
              #!/usr/bin/env bash
              set -ex

              # wait for port-forward to be ready
              timeout 5m bash -c 'until echo > /dev/tcp/localhost/8000; do sleep 2s; done' || {
                echo "[ERROR] Port-forward is not ready. Exiting."
                exit 1
              }

              # ENABLE_HTTPS is set to false in service-template for this test 
              # when the clusters only have self-signed certificates.
              # This option should not be used in production.

              BASE_URL="http://127.0.0.1:8000"
              CONFIG_PATH="/workspace/config.yaml"

              # Download ocm CLI binary
              curl -L -o /tmp/ocm https://github.com/openshift-online/ocm-cli/releases/download/v1.0.3/ocm-linux-amd64
              chmod +x /tmp/ocm

              # Download jq binary
              curl -L -o /tmp/jq https://github.com/jqlang/jq/releases/download/jq-1.7.1/jq-linux-amd64
              chmod +x /tmp/jq

              export PATH=$PATH:/tmp

              /tmp/ocm login --token=${OCM_TOKEN} --url=${BASE_URL}

              AUTH_RESPONSE=$(/tmp/ocm get /api/rh-trex/v1/dinosaurs)

              # Print the response to the logs
              echo "${AUTH_RESPONSE}" | jq '.items[]' || echo "No dinosaurs found or failed to parse the response."

              AUTH_URL="${BASE_URL}/api/rh-trex/v1/dinosaurs"
              echo -n "${AUTH_URL}" | tee $(results.authenticated_url.path)
              echo -n "${CONFIG_PATH}" | tee $(results.config_path.path)
          - name: run-rapiddast
            image: quay.io/redhatproductsecurity/rapidast:latest
            env:
              - name: OCM_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: ocm
                    key: ocmtoken
            script: |
              #!/usr/bin/env bash
              set -ex

              # ENABLE_HTTPS is set to false in service-template to allow the scan to run against the port-forwarded service

              curl -L -o /tmp/ocm https://github.com/openshift-online/ocm-cli/releases/download/v1.0.3/ocm-linux-amd64
              chmod +x /tmp/ocm
              export PATH=$PATH:/tmp

              AUTH_URL=$(cat /tekton/results/authenticated_url)
              CONFIG_PATH="/workspace/config.yaml"
              RESULTS_DIR="/tmp/results"
              LOCAL_OPENAPI_PATH="/workspace/openapi.yaml"

              # Fetch the local `openapi.yaml` file from the repository
              curl -L -o ${LOCAL_OPENAPI_PATH} https://raw.githubusercontent.com/jencull/rh-trex/main/openapi/openapi.yaml || {
                echo "[ERROR] Failed to download the OpenAPI spec from the repository."
                exit 1
              }

              mkdir -p ${RESULTS_DIR}
              chmod o+w ${RESULTS_DIR}

              # Create the RapiDAST configuration file
              cat <<EOF > ${CONFIG_PATH}
                config:
                  configVersion: 5

                application:
                  shortName: "multiarch-tuning-operator"
                  url: "${AUTH_URL}"  # Base URL for the application under test

                general:
                  authentication:
                    type: http_header
                    parameters:
                      name: Authorization
                      value_from_var: OCM_TOKEN

                scanners:
                  zap:
                    apiScan:
                      apis:
                        apiFile: "${LOCAL_OPENAPI_PATH}" # Path to the OpenAPI spec
                      resultsDir: "${RESULTS_DIR}"  # Directory to store scan results
                    activeScan:
                      policy: "API-scan-minimal"  # predefined minimal policy for active scanning
                    report:
                      format: ["json", "html"]  # Generate JSON and HTML reports
                    miscOptions:
                      zapPort: 8080  # Default ZAP port
                      memMaxHeap: "2048m"  # Reduced heap size for minimal application
              EOF

              # run scan
              ./rapidast.py --config ${CONFIG_PATH}

              echo "RapiDAST scan completed. Checking results..."
              FINAL_RESULTS_DIR=$(find ./results -type d -name "DAST-*" -print -quit)
              if [ -z "$FINAL_RESULTS_DIR" ]; then
                echo "[ERROR] No results directory found. Check the scan configuration."
                exit 1
              fi

              echo "[INFO] Results found in: ${FINAL_RESULTS_DIR}"
              ls -l ${FINAL_RESULTS_DIR}